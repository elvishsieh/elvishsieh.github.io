<!doctype html>
<html lang="zh-Hant-TW">

<head>
<meta charset="utf-8">

<title>åˆ†é¡ - Decision Tree</title>

<meta name="description" content="Tutorial of web design for primer">
<meta name="author" content="Elvis Hsieh">

<meta name="apple-mobile-web-app-capable" content="yes" />
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

<link rel="stylesheet" href="/revealjs/dist/reset.css">
<link rel="stylesheet" href="/revealjs/dist/reveal.css">
<link rel="stylesheet" href="/revealjs/dist/theme/black.css" id="theme">
<link rel="stylesheet" href="/revealjs/plugin/chalkboard/style.css">
<link rel="stylesheet" href="/revealjs/plugin/customcontrols/style.css">
<link rel="stylesheet" href="/css/custom4revealjs.css">
<!-- Code syntax highlighting -->
<link rel="stylesheet" href="/highlightjs/styles/monokai.min.css">   
<link rel="stylesheet" href="/css/style4font.css">
<!-- Printing and PDF exports -->
<script>
var link = document.createElement( 'link' );
link.rel = 'stylesheet';
link.type = 'text/css';
link.href = window.location.search.match( /revealjs/print-pdf/gi ) ? '/revealjs/dist/print/pdf.css' : '/revealjs/dist/print/paper.css';
document.getElementsByTagName( 'head' )[0].appendChild( link );
</script>

<!--[if lt IE 9]>
<script src="reveal-js/lib/js/html5shiv.js"></script>
<![endif]-->
</head>
<body>

<div class="reveal">

<!-- Any section element inside of this container is displayed as a slide -->
<div class="slides">

<section><!--start block-->
<section data-markdown><script type="text/template">
# Classification
</script>
</section>
<section data-markdown><script type="text/template">
## What is Classification?
- ä¸€ä½è²¸æ¬¾çš„éŠ€è¡Œè¡Œå“¡ï¼Œå¥¹éœ€è¦å°æ–¼å¥¹è²¸æ¬¾å®¢æˆ¶è³‡æ–™ä½œåˆ†æï¼Œé€éè²¸æ¬¾å®¢æˆ¶è³‡æ–™ä½œåˆ†æèˆ‡å­¸ç¿’ï¼Œé€²è€Œäº†è§£é‚£äº›è²¸æ¬¾å®¢æˆ¶çš„å®‰å…¨çš„ï¼Œé‚£äº›æ˜¯æœ‰é¢¨éšªçš„ï¼Ÿ
- *AllElectronics* é€™å®¶å…¬å¸çš„éŠ·å”®ç¶“ç†ä»–éœ€è¦åšè³‡æ–™åˆ†æï¼Œå°æ–¼å·²çŸ¥æŸä¸€ä½é¡§å®¢å€‹äººè³‡æ–™çš„æƒ…æ³ä¸‹ï¼ŒçŒœæ¸¬é¡§å®¢æ˜¯å¦æœƒè³¼è²·é›»è…¦ï¼Ÿ
- åœ¨ä¸Šé¢çš„ä¾‹å­ä¸­ï¼Œå°è³‡æ–™ä½œåˆ†æçš„å·¥ä½œï¼Œæ˜¯å°±æ˜¯ä¸€ç¨®åˆ†é¡çš„å‹•ä½œï¼Œè€Œä¸€å€‹æ¨¡å‹æˆ–åˆ†é¡å™¨è¢«å»ºæ§‹æˆä¸€ç¨®**é æ¸¬é¡åˆ¥çš„å·¥å…·**ï¼Œæ¨™è¨»äº†é‚£äº›å®¢æˆ¶æ˜¯æœ‰é¢¨éšªçš„ï¼Œé‚£äº›é¡§å®¢å¯èƒ½è³¼è²·é›»è…¦ï¼Ÿ
- æ—¥å¸¸ç”Ÿæ´»ä¸­ï¼Œæˆ‘å€‘ä¹Ÿç¶“å¸¸åšåˆ†é¡ï¼Œæœ‰äº›**éœ€è¦ç¶“é©—(å­¸ç¿’)æ‰èƒ½åšåˆ†é¡**ï¼Œä¾‹å¦‚è¥¿ç“œæ˜¯å¦æœƒç”œï¼Ÿç“œçš„å¤§å°ã€é¡è‰²ã€æ•²æ“Šçš„è²éŸ³ç­‰(**åˆ†é¡ (Classification)ã€ç›£ç£å¼**)ï¼›æœ‰äº›å‰‡**ä¸éœ€è¦ç¶“é©—**ï¼Œä»¥ä¸€ç¨®é‡æ¸¬æ¨™æº–ä¾†åˆ†é¡ï¼Œä¾‹å¦‚é‡é‡ã€é•·åº¦ç­‰(**åˆ†ç¾¤(Clustering)ã€éç›£ç£å¼**)
</script></section>
<section data-markdown><script type="text/template">
## [Supervised vs. Unsupervised](./01intro.html#/4/2) Learning
- **Supervised(ç›£ç£) learning** (classification)
	- Supervision: The **training data** (observations, measurements, etc.) are **accompanied by labels indicating the class of the observations**
	- New data is classified based on the training set
- **Unsupervised learning** (clustering)
	- The class **labels** of training data is **unknown**
	- Given a set of measurements, observations, etc. with the aim of establishing the existence of classes or clusters in the data
</script></section>
<section data-markdown><script type="text/template">
## Prediction Problems
- **Classification**
	- predicts categorical(æ˜ç¢ºçš„) class labels discrete(é›¢æ•£çš„) or nominal(æœ‰åç›®çš„)
	- classifies data (constructs(å»ºæ§‹) a model) based on the training set and the values (class labels) in a classifying attribute and uses it in classifying new data
- **Numeric(æ•¸å­—) Prediction**  
	- models continuous-valued functions, i.e., **predicts unknown or missing values** 
- **Typical applications**
	- Credit/loan(è²¸æ¬¾) approval(è´Šæˆ)
	- Fraud(æ¬ºè©) detection: if a transaction is fraudulent
	- Web page categorization: which category(åˆ†é¡) it is
</script></section>
<section data-markdown><script type="text/template">
## Classification Process (1/2)
- **Model construction**: describing a set of predetermined classes
	- Each tuple/sample is assumed to belong to a predefined class, as determined by the class label attribute.
	- The set of tuples used for model construction is training set(è¨“ç·´è³‡æ–™é›†)
	- The **model** is represented as **classification rules**, **decision trees**, or **mathematical formulae**
- If the test set is used to **select models**, it is **called validation (test) set(é©—è­‰è³‡æ–™é›†)**. 
</script></section>
<section data-markdown><script type="text/template">
## Classification Process (2/2)
- Model usage: for **classifying future or unknown objects**
	- **Estimate accuracy** of the model
		- The known label of test sample is compared with the classified result from the model
		- Accuracy rate is the percentage of test set samples that are correctly classified by the model
		- **Test set is independent**(ç¨ç«‹çš„) of training set (**otherwise overfitting**(éåº¦é©åˆ)) 
- If the **accuracy is acceptable**(æº–ç¢ºæ€§æ˜¯å¯ä»¥æ¥å—çš„), use the model to **classify new data**
</script></section>
<section data-markdown><script type="text/template">
## Process 1 - Model Construction
- æ•™æˆæˆ–å¹´è³‡ > 6 å¹´çš„äººï¼Œä»»æœŸçš„æ¬„ä½"æ˜¯(Yes)"
![](/images/datamining/modeling.png)
</script></section>
<section data-markdown><script type="text/template">
## Process 2 - Prediction
- æ‹¿å·²ç¶“åˆ†é¡å¥½çš„è³‡æ–™é›†ï¼Œé æ¸¬ Jeff è€å¸«çš„è³‡æ–™
![](/images/datamining/classifier.png)
</script></section>
<section data-markdown><script type="text/template">
## Classification Algorithm(åˆ†é¡æŠ€è¡“)
- Decision Tree(æ±ºç­–æ¨¹) âœ…ğŸŸ 
- Random Forest(éš¨æ©Ÿæ£®æ—) âœ…ğŸŸ 
- Logistic Regression(ç¾…å‰æ–¯å›æ­¸)âœ…ğŸŸ 
- Support Vector Machines, SVM(æ”¯æŒå‘é‡æ©Ÿ)âœ…ğŸŸ 
- K-Nearest Neighbors, KNN(K å€‹æœ€è¿‘é„°å±…æ³•)âœ…ğŸŸ 
- Neural Network(é¡ç¥ç¶“ç¶²è·¯)âœ…ğŸŸ 
- Naive Bayes(è²æ°åˆ†é¡æ³•)âœ…ğŸŸ 
- CN2 rule Induction(CN2 è¦å‰‡æ­¸ç´æ³•)ğŸŸ 
- <span style="padding-left: 100pt"> $\vdots$</span>
- âœ… [Python code çš„æ¼”ç®—æ³•](https://github.com/f2005636/Classification)ï¼›ğŸŸ Orange æœ‰æ”¯æ´çš„æ¼”ç®—æ³•
- PyCaret is a Python package for ML which have compressed in my Orange.7z file. [PyCaret's Cheat sheet](https://pycaret.gitbook.io/docs/learn-pycaret/cheat-sheet)
</script></section>
</section><!--end block-->

<section><!--start block-->
<section data-markdown><script type="text/template">
# Decision Tree
</script></section>
<section data-markdown><script type="text/template">
## An example of Decision Tree(1/2)
- Training data set: **Buys_computer**
- The data set follows an example of **Quinlan's ID3**
![](/images/datamining/decisionTable.png)
</script></section>
<section data-markdown><script type="text/template">
## An example of Decision Tree(2/2)
![](/images/datamining/decisionTree.png)
</script></section>
<section data-markdown><script type="text/template">
## Decision tree learning(1/2)
- Basic algorithm (a greedy(è²ªå©ª) algorithm)
	- Tree is constructed in a **top-down** recursive(éè¿´) divide-and-conquer(å¾æœ) manner
	- **At start**, all the training examples are **at the root**
	- Attributes are **categorical(æ˜ç¢ºçš„)** (if continuous-valued, they are discretized in advance)
	- Examples are **partitioned(åˆ†å‰²) recursively** based on selected attributes
	- Test attributes are selected on the basis of a **heuristic(å•Ÿç™¼) or statistical measure** (e.g., information gain) 
</script></section>
<section data-markdown><script type="text/template">
## Decision tree learningr(2/2)
- Conditions for **stopping partitioning**
	- All samples for a **given node belong to the same class**
	- There are no remaining attributes for further partitioning â€“ majority voting(è¡¨æ±º) is employed for **classifying the leaf(æ¨¹è‘‰)**
	- There are no samples left
</script></section>
<section data-markdown><script type="text/template">
## Types of decision tree
- **Classification tree analysis** is when the predicted outcome(é æ¸¬çµæœ) is **the class (discrete)** to which the data belongs.
- **Regression tree analysis** is when the predicted outcome can be considered a real number (e.g. the price of a house, or a patient's length of stay in a hospital).
- Notable decision tree algorithms(è‘—åçš„æ±ºç­–æ¨¹ç®—æ³•)
	- ID3 (Iterative Dichotomiser 3, è¿­ä»£äºŒåˆ†æ³•)
	- C4.5 (successor(æ¥ç­äºº) of ID3)ã€C5.0
	- CART (Classification And Regression Tree); 
	- [Chi-square(`$\chi^2$`, å¡æ–¹æª¢å®š)](./06preprocessing.html#/3/4) automatic interaction detection (CHAID). Performs multi-level splits when computing classification trees.
</script></section>
<section data-markdown><script type="text/template">
## Decision Tree Algorithm(1/2)
- **Algorithm: Generate decision tree.** Generate a decision tree from the training tuples of data partition, D.
- **Input:**
	- Data partition, D, which is a set of training tuples and their associated class labels;
	- attribute list, the set of candidate attributes;
	- Attribute selection method, a procedure to determine the splitting criterion that â€œbestâ€
	- partitions the data tuples into individual classes. This criterion consists of a
	- splitting attribute and, possibly, either a split-point or splitting subset.
</script></section>
<section data-markdown><script type="text/template">
## Decision Tree Algorithm(2/2)
- **Output:** A decision tree.
- **Method:**
<pre><code data-trim data-line-numbers>
 create a node N;
 if tuples in D are all of the same class, C, then
 	return N as a leaf node labeled with the class C;
 if attribute_list is empty then
 	return N as a leaf node labeled with the majority class in D; // majority voting
 apply Attribute_selection_method(D, attribute_list) to find the â€œbestâ€ splitting_criterion;
 label node N with splitting_criterion;
 if splitting_attribute is discrete-valued and
	  multiway splits allowed then // not restricted to binary trees
 	 attribute_list ğŸ  attribute_list â€“ splitting_attribute; // remove splitting attribute
 for each outcome j of splitting_criterion
 	// partition the tuples and grow subtrees for each partition
 	let Dj be the set of data tuples in D satisfying outcome j; // a partition
 	if Dj is empty then
 		attach a leaf labeled with the majority class in D to node N;
 	else attach the node returned by Generate decision tree(Dj , attribute_list) to node N;
 end for
 return N;
</code></pre>
</script></section>
</section><!--end block-->

<section><!--start block-->
<section data-markdown><script type="text/template">
# Attribute Selection Measures
</script></section>
<section data-markdown><script type="text/template">
## Best partition for Attribute Selection
- What is **the best separates** a given data partition, D? **How to partition** a given datasets into individual classes?
- An attribute selection measure is a heuristic(å•Ÿç™¼) for selecting the splitting criterion(æ¨™æº–) that â€œbestâ€ separates a given data partition, D, of class-labeled training tuples into individual classes.
- **Attribute selection measures** are also known as splitting rules because they **determine how the tuples at a given node are to be split**.
- Three popular attribute selection measuresâ€”**information gain, gain ratio, and Gini index**.
</script></section>
<section data-markdown><script type="text/template">
## Information Gain(è³‡è¨Šç²ç›Š, 1/3)
- Let **`$D$`, the data partition**(åˆ†å‰²), be a training set of class-labeled tuples. Suppose the class label attribute has `$m$` distinct values defining **`$m$`
distinct classes(ä¸åŒé¡), `$C_i$`** (for `$i = 1, \cdots , m$`). Let **`$C_{i, D}$` be the set of tuples(ç´€éŒ„) of class `$C_i$`** in `$D$`. Let **`$|C_{i, D}|$`** and **`$|C_{i,D}|$`** 
denote the **number of tuples** in `$D$` and `$C_{i,D}$`, respectively.
- **Expected information(`$Info(D)$`)** is also known as the entropy(ç†µ) of `$D$`
	`$$
	\fcolorbox{red}{gray} {$\cal Info(D) = - p_i \cdot\sum^m_1 \log_2 (p_i)$}
	$$`
</script></section>
<section data-markdown><script type="text/template">
## Information Gain(è³‡è¨Šç²ç›Š, 2/3)
- where `$p_i$` is the nonzero probability that an arbitrary tuple in `$D$` belongs to class `$C_i$` and is estimated by `$|C_{i, D}|/|D|$`
- **ID3 uses information gain** as its attribute selection measure.
- åœ¨**è³‡è¨Šç†è«–(information theroy)ä¸­**ï¼Œç†µ(entropy)æ˜¯æ¥æ”¶çš„æ¯æ¢æ¶ˆæ¯ä¸­**åŒ…å«çš„è³‡è¨Šçš„å¹³å‡é‡**ï¼Œåˆè¢«ç¨±ç‚º**è³‡è¨Šç†µ**ã€‚
- **ç†µ(entropy)çš„å€¼è¶Šå¤§**ï¼Œè¡¨ç¤ºè³‡æ–™çš„è®Šå‹•æ€§è¶Šå¤§ï¼Œ**ä¸ç¢ºå®šæ€§é«˜**ï¼›ç†µ(entropy)çš„å€¼è¶Šå°ï¼Œè¡¨ç¤ºè³‡æ–™çš„è®Šå‹•æ€§è¶Šå°ï¼Œ**ä¸ç¢ºå®šæ€§ä½**ã€‚
- ç†µ(entropy)å¯ä»¥ç†è§£ç‚º**ä¸ç¢ºå®šæ€§çš„é‡åº¦**ï¼Œä¸æ˜¯ç¢ºå®šæ€§çš„é‡åº¦ï¼Œè¶Šéš¨æ©Ÿ(äº‚)çš„è³‡è¨Šé‡ Entropy å€¼è¶Šå¤§ã€‚
</script></section>
<section data-markdown><script type="text/template">
## Information Gain(è³‡è¨Šç²ç›Š, 3/3)
- Information needed (after using `$A$` to split `$D$` into `$v$` partitions) to classify `$D$`
`$$
	\cal info_A (D) = \sum_{j=1}^v \frac{|D_j|}{|D|} \times info(D)
$$`
- Information gained by branching(åˆ†æ”¯) on attribute `$A$`:
`$$
	\cal Gain(A) = info(D) - info_A(D)
$$`
</script></section>
<section data-markdown><script type="text/template">
## Example of Information Gain(1/5)
- Table 8.1 presents a training set,D, of class-labeled tuples randomly selected from the AllElectronics customer *DB*.
![](/images/datamining/decisionTable.png)
</script></section>
<section data-markdown><script type="text/template">
## Example of Information Gain(2/5)
- The class label attribute, buys computer, has two distinct values (namely, *{yes, no}*); ie, `$m = 2$`.
- We first use the entropy formula to compute the expected information needed to classify a tuple in D
`$$
	\cal Info(D) = - \frac{9}{14} \log_2 (\frac{9}{14}) - \frac{5}{14} \log_2 (\frac{5}{14}) = 0.940
$$`
- For the **age category â€œyouth,â€** there are **two yes** tuples and **three no** tuples.
`$$
	\cal I_{youth}(2, 3) = - \frac{2}{5} \log_2 (\frac{2}{5}) - \frac{3}{5} \log_2 (\frac{3}{5}) = 0.971
$$`
</script></section>
<section data-markdown><script type="text/template">
## Example of Information Gain(3/5)
- For the **age category â€œmiddle_age,â€** there are **four yes** tuples and **zero no** tuples. <br/>
`$ \;\therefore
	\cal I_{middle\_age}(4, 0) = - \frac{4}{4} \log_2 (\frac{4}{4}) - \frac{0}{4} \log_2 (\frac{0}{4}) = 0
$`
- For the **age category â€œsenior,â€** there are **three yes** tuples and **two no** tuples.
`$ \;\therefore
	\cal I_{youth}(3, 2) = - \frac{3}{5} \log_2 (\frac{3}{5}) - \frac{2}{5} \log_2 (\frac{2}{5}) = 0.971
$`
- The expected information needed to classify a tuple in D if the tuples are **partitioned according to age** is
`$$
	\begin{align*}
	\cal Info_{age}(D) &= \frac{5}{14}\cdot I(2,3) + \frac{9}{14}\cdot I(4,0) + \frac{5}{14} I(3,2) \\
					&= 0.357\times 0.971 + 0 + 0.357\times 0.971 = 0.694
	\end{align*}
$$`
</script></section>
<section data-markdown><script type="text/template">
## Example of Information Gain(4/5)
- Hence, the gain in information from such a partitioning would be
`$$
	\begin{align*}
	\cal Gain(A) &= info(D) - info_{age}(D)\\
				&= 0.940 - 0.694 = 0.246
	\end{align*}
$$`
- Similarly, we can compute `$Gain_{(income)} = 0.029$` bits, `$Gain_{student} = 0.151$` bits,
and `$Gain_{credit\_rating} = 0.048$` bits. 
- Because **age has the highest information gain** among the attributes, it is selected as the splitting attribute.
</script></section>
<section data-markdown><script type="text/template">
## Example of Information Gain(5/5)
![](/images/datamining/decisionSplit.png)
</script></section>
</section><!--end block-->

<section><!--start block-->
<section data-markdown><script type="text/template">
# Gain Ratio <br /> and <br /> Gini Index
</script></section>
<section data-markdown><script type="text/template">
## Gain Ratio(1/3)
- How can we **compute the information gain** of an attribute that is **continuous valued**, unlike in the example?
- Must determine **the best split point** for A
	- Sort the value A in increasing order
	- Typically, the midpoint between each pair of adjacent values is considered as a possible split point
		- **`$(a_i+a_{i+1})/2$`** is the midpoint between the values of `$a_i$` and `$a_{i+1}$`
	- **The point with the minimum expected information requirement for A** is selected as the split-point for A
- Split:
`$D_1$` is the set of tuples in `$D$` satisfying `$A \leq$` split-point, and `$D_2$` is satisfying `$A >$` split-point
</script></section>
<section data-markdown><script type="text/template">
## Gain Ratio(2/3)
- Information gain measure is biased towards attributes with **a large number(æ•¸é‡å¤§)** of values, i.e., **product ID(1-14)** as above example.
- C4.5 (a successor of ID3) **uses gain ratio to overcome the problem** (normalization to information gain)
- **Split information** value defined analogously with `$\cal Info(D)$` as
`$$
	\fcolorbox{red}{gray} {$\cal SplitInfo_A(D) = - \displaystyle\sum^v_1 \frac{|D_j|}{|D|} \times \log_2 (\frac{|D_j|}{|D|})$} 
$$`
</script></section>
<section data-markdown><script type="text/template">
## Gain Ratio(3/3)
- The gain ratio is defined as 
`$$ GainRatio(A) = \frac{Gain(A)}{SplitInfo(A)}$$`
- The attribute with the **maximum gain ratio is selected** as the splitting attribute.
- Note, however, that as the split information approaches **0, the ratio becomes unstable**.
- A **constraint(é™åˆ¶) is added** to avoid this, whereby the information gain of the test selected must be largeâ€”**at least as great as the average gain** over all tests examined.
</script></section>
<section data-markdown><script type="text/template">
## An example of Gain Ratio(1/2)
- Computation of gain ratio for **the attribute income**. A test on income splits the data of
[Table 8.1](./08decisionTree.html#/2/5) into three partitions, namely **low, medium, and high**, containing **four, six, and
four tuples**, respectively.
- To compute the gain ratio of income, we first use [the Equation](./08decisionTree.html#/3/2) to obtain
`$$
\begin{align*}
SplitInfo_A(D) = &- \frac{4}{14} \times \log_2 (\frac{4}{14}) - \frac{6}{14} \times\log_2 (\frac{6}{14}) \\
			     & - \frac{4}{14} \times\log_2 (\frac{4}{14})\\
			   =& \;1.557
\end{align*}
$$`
</script></section>
<section data-markdown><script type="text/template">
## An example of Gain Ratio(2/2)
- From [the above example](./08decisionTree.html#/2/8), we have 
`$$Gain(income) = 0.029$$`
- Therefore, 
`$$
	\begin{align*}
		GainRatio(income) &= 0.029/1.557 \\
					&= 0.019
	\end{align*}
$$`
</script></section>
</section><!--end block-->

<section><!--start block-->
<section data-markdown><script type="text/template">
## Gini index(1/3)
- The Gini index is used in **CART(Classification and Regression Tree)**.
- The Gini index **measures the impurity(ä¸ç´”)** of `$D$`, a data partition or set of training tuples,
`$$
\cal Gini(D) = 1- \displaystyle\sum^m_{i = 1} p^2_i
$$`
- where `$p_i$` is the probability that a tuple in `$D$` belongs to class `$C_i$` and is estimated by `$|C_{i,D}|/|D|$`. 
The sum is computed over `$m$` classes.
</script></section>
<section data-markdown><script type="text/template">
## Gini index(2/3)
- If a data set `$D$`  is split on *A* into two subsets `$D_1$` and `$D_2$`, the **gini index `$gini(D)$` is defined** as
`$$
\cal Gini_A(D) = \frac{|D_1|}{|D|} Gini(D_1) + \frac{|D_2|}{|D|} Gini(D_2)
$$`
- For each attribute, each of the **possible binary splits is considered.**
- For a **discrete-valued attribute**, the subset that gives the **minimum Gini index** for that attribute is selected as its splitting subset.
</script></section>
<section data-markdown><script type="text/template">
## Gini index(3/3)
- For **continuous-valued** attributes, each possible split-point must be considered. The strategy is **similar to** that described earlier 
for information gain, where the **midpoint between each pair of (sorted) adjacent values** is taken as a possible split-point.
- **Reduction in impurity** that would be incurred by a binary split on a discrete or continuous-valued attribute *A* is
`$$
\Delta \cal Gini(A) = Gini(D) - Gini_A(D)
$$`
- The attribute provides the smallest `$gini_{split}(D)$` (or **the largest reduction in impurity**) is chosen to split the node.
</script></section>
<section data-markdown><script type="text/template">
## An example of Gini index(1/3)
- Let `$D$` be the training data shown earlier in [Table 8.1](./08decisionTree.html#/2/5) , where there are **nine tuples** belonging to the *class_buys
 _computer = yes* and the remaining **five tuples** belong to the *class_buys_computer = no*. A (root) node `$N$` is created for the tuples in `$D$`.
- We first use [the Equation](./08decisionTree.html#/4) for the Gini index to compute the impurity of `$D$`:
`$$
Gini(D) = 1- (\frac{9}{14})^2 - (\frac{9}{14})^2 
$$`
</script></section>
<section data-markdown><script type="text/template">
## An example of Gini index(2/3)
- To find the splitting criterion for the tuples in D, we need to compute the Gini index for each attribute.
`$$
\begin{align*}
Gini& _{income\in \{low, medium\}} (D) \\
			 &= \frac{10}{14} Gini(D_1) + \frac{4}{14} Gini(D_2) \\
			 &= \frac{10}{14} \left(1- (\frac{7}{10})^2 - (\frac{3}{10})^2\right) + \frac{4}{14} \left(1- (\frac{2}{4})^2 - (\frac{2}{4})^2\right)\\
			 &= 0.443 \\
			 &= Gini_{income\in \{high\}} (D)
\end{align*}
$$`
</script></section>
<section data-markdown><script type="text/template">
## An example of Gini index(3/3)
- Similarly, the Gini index values are 0.458(for the subsets`$\{low, high\}$` and `$\{medium\}$`) and 0.450 (for the subsets `$\{medium, high\}$` and `$\{low\}$`).
- Therefore, the **best binary split** for attribute **`$income$` is on `$\{low, medium\}$`** (or `$\{high\}$`) because it minimizes.
- the attributes `$age, student$` and `$credit\_rating$` are both binary, with **Gini index values of 0.375, 0.367 and 0.429, respectively**.
- The attribute **`$age$` and splitting subset `$\{youth, senior\}$`** therefore give the **minimum Gini index overall**, with a reduction in impurity of `$0.459- 0.357 = 0.102$`.
</script></section>
<section data-markdown><script type="text/template">
## Comparing Attribute Selection Measures
- The three measures, in general, return good results but
	- Information gain: 
		- biased towards **multivalued attributes**
	- Gain ratio: 
		- tends to **prefer unbalanced splits** in which **one partition is much smaller than the others**
	- Gini index: 
		- biased to **multivalued attributes**
		- has difficulty when **number of classes is large**
		- tends to favor tests that result in **equal-sized partitions** and **purity in both partitions**
</script></section>
<section data-markdown><script type="text/template">
## Other Attribute Selection Measures
- CHAID: a popular decision tree algorithm, measure based on `$\chi^2$` test for independence
- C-SEP: performs better than info. gain and gini index in certain cases
- G-statistic: has a close approximation to `$\chi^2$` distribution 
- MDL (Minimal Description Length) principle (i.e., the simplest solution is preferred): 
- Multivariate splits (partition based on multiple variable combinations, e.g. CART)
- Which attribute selection measure is the best? Most **give good results**, **none is significantly superior** than others
</script></section>
</section><!--end block-->
<section><!--start block-->
<section data-markdown><script type="text/template">
# Overfitting <br />and<br /> Tree Pruning
</script></section>
<section data-markdown><script type="text/template">
## Overfitting
- è¯åˆå¤§å­¸é™³å£«æ°è€å¸«åœ¨[æ±ºç­–æ¨¹å­¸ç¿’](http://debussy.im.nuu.edu.tw/sjchen/MachineLearning/final/CLS_DT.pdf)æŠ•å½±ç‰‡ p.41 ä¸­å¯«åˆ°ï¼š
- ä¸‹ï¦œçš„ä¾‹å­æ˜¯ä¸€å€‹éƒ¨å±¬çš„æˆåŠŸç¶“é©—
	1) å¥‰æ‰¿ A ä¸Šå¸ â‡› ä¸Šå¸é«˜èˆˆ
	2) é€ï¦¶çµ¦ A ä¸Šå¸ â‡› ä¸Šå¸ï¤é«˜èˆˆ
	3) **æŒ‰æ‘© A ä¸Šå¸è‚©è†€ â‡› ä¸Šå¸éï¨é«˜èˆˆ**
- ä½†æ˜¯å› ç‚ºäººäº‹ï¥¢å‹•ï¼ŒB ä¸Šå¸åˆ°ä»»ï¼Œç•¶ï§ç”¨åŸæœ¬çš„ç¶“é©—æ™‚ï¼š
	1) å¥‰æ‰¿ B ä¸Šå¸ â‡› ä¸Šå¸é«˜èˆˆ
	2) é€ï¦¶çµ¦ B ä¸Šå¸ â‡› ä¸Šå¸ï¤é«˜èˆˆ
	3) **æŒ‰æ‘© B ä¸Šå¸è‚©è†€ â‡› ä¸Šå¸èªç‚ºæ˜¯æ€§é¨·æ“¾å¾ˆç”Ÿæ°£**
- å¾ä¸Šé¢çš„ï¦µå­çœ‹èµ·ï¤­**ï¥§æ˜¯æ‰€æœ‰çš„ä¸Šå¸è¢«æŒ‰æ‘©è‚©è†€ï¨¦æœƒé«˜èˆˆ**ï¼Œåªæœ‰ A ä¸Šå¸æ‰æœƒé«˜èˆˆï¼Œ**ï¥´å°‡ A ä¸Šå¸çš„ï¦µå­ï¦œç‚ºå®šï§˜ä¸¦å­¸ç¿’èµ·ï¤­ï¼Œå°±æœƒè®Šæˆéï¨å­¸ç¿’**ã€‚
</script></section>
<section data-markdown><script type="text/template">
## Overfitting and Tree Pruning
- Overfitting:  An induced tree may overfit the training data	
	- **Too many branches**, some may reflect anomalies due to **noise or outliers**
	- **Poor accuracy** for unseen samples
- Two approaches to avoid overfitting 
	- **Prepruning**: Halt tree construction early Ìµ do not split a node if this would result in the goodness measure falling below a threshold
		- **Difficult** to choose an **appropriate threshold**
	- **Postpruning**: Remove branches from a â€œfully grownâ€ treeâ€”get a sequence of progressively pruned trees
		- Use a set of **data different from the training data** to decide which is the â€œbest pruned treeâ€
</script></section>
</section><!--end block-->

<section><!--start block -->
<section data-markdown><script type="text/template">
# Model Evaluation<br /> and Selection
</script></section>
<section data-markdown><script type="text/template">
## Model Evaluation(æ¨¡å‹è©•ä¼°)
- Evaluation metrics(æŒ‡æ¨™): How can we measure accuracy(æº–ç¢ºæ€§)?  Other metrics to consider?
- Use **validation test set(é©—è­‰æ¸¬è©¦è³‡æ–™) of class-labeled tuples instead of training set** when assessing accuracy
- Methods for estimating(ä¼°ç®—) a classifier's accuracy: 
	- **Holdout(æˆªç•™)** method, random subsampling
	- **Cross-validation**(äº¤å‰é©—è­‰)
	- **Bootstrap**(è‡ªèˆ‰ or æ‹”é´æ³•)
- Comparing classifiers(åˆ†é¡å™¨çš„æ¯”è¼ƒ):
	- Confidence intervals(ä¿¡è³´å€é–“)
	- Cost-benefit(æˆæœ¬æ•ˆç›Š) analysis and **AUC(Area Under of ROC)** or **PR**(Precision-Recall) Curves
</script></section>
<section data-markdown><script type="text/template">
## Confusion Matrix(æ··æ·†çŸ©é™£)
- `$$
\begin{array}{cc|cc}
~ & ~ & é æ¸¬ & ~ \\
Total & = P + N & Positive(PP) & Negative(NN) \\ \hline
~ & ~ & ~ & ~ \\ 
 ~ & Positive(P) & TP &  FN\\
å¯¦éš› & ~ & & ~ \\
~ & Negative(N) & FP & TN
\end{array}
$$`	
<p class="fragment">where TP: True Positive, <b>FP: False Positive, FN: False Negative</b>, TN: True Negative</p>
</script></section>
<section data-markdown><script type="text/template">
## Example of Confusion Matrix(1/2)
- ä½¿ç”¨ PCR or å¿«ç¯©è©¦åŠ‘**æª¢æ¸¬æ˜¯å¦æ„ŸæŸ“** Covid-19 ç—…æ¯’
	- æ„ŸæŸ“/é‚„æ²’æ„ŸæŸ“çš„äººåšæª¢æ¸¬ï¼Œ**çµæœä¸€å®šåªæœ‰å…©ç¨®**ï¼šä¸æ˜¯**é™°æ€§(Negative)**ï¼Œå°±æ˜¯**é™½æ€§(Positive)**
	- çµæœ 1: **é™½æ€§(Positive)**
		- æ„ŸæŸ“çš„äººç¢ºå¯¦ç¢ºè¨ºï¼š True Positive(TP)
		- æ²’æœ‰æ„ŸæŸ“çš„äºº**ç¢ºè¨º**ï¼š False Positive(FP,å½é™½æ€§)
	- çµæœ 2: **é™°æ€§(Negative)**
		- æ„ŸæŸ“çš„äºº**æ²’æœ‰ç¢ºè¨º**ï¼š False Negative(FN, å½é™°æ€§)
		- æ²’æœ‰æ„ŸæŸ“çš„äººç¢ºå¯¦æ²’æœ‰ç¢ºè¨ºï¼š True Negative(TN)
</script></section>
<section data-markdown><script type="text/template">
## Example of Confusion Matrix(2/2)
- `$$
\begin{array}{c|cc|c}
~ & é æ¸¬ & (predicted) & ~ \\ \hline
å¯¦éš› & é™½æ€§ & é™°æ€§ & Total\\
æ„ŸæŸ“ & 259 & 41 & 300\\
æ²’æœ‰æ„ŸæŸ“ & 22 & 278  & 300 \\ \hline
Total & 281 & 319 & 600
\end{array}
$$`	
- å½é™½æ€§(FP)äººæ•¸ï¼š22 äººï¼›å½é™°æ€§(FN)äººæ•¸:41äºº
- åœ¨ 300 ä½é™½æ€§ç¢ºè¨ºçš„äººï¼Œæœ‰ 41 ä½è¢«èª¤åˆ¤æˆé™°æ€§ï¼Œé€™**å½é™°æ€§**æª¢æ¸¬çµæœæ˜¯**å¿…é ˆè¦é‡è¦–çš„å•é¡Œ**ã€‚
- å¦‚æœé€™æ˜¯ä¸€çµ„**ç™Œç—‡çš„æª¢æ¸¬**çµæœï¼Œå°æ–¼**å½é™½æ€§**ä¹Ÿæ˜¯ä¸€ä»¶æŒºåš‡äººçš„äº‹æƒ…ã€‚
</script></section>
</section><!--end block-->

<section><!--start block-->
<section data-markdown><script type="text/template">
# Classifier Evaluation Metrics
</script></section>
<section data-markdown><script type="text/template">
## Evaluation Metrics
| *Measure*  								| *Formula* |
|:---										| :---:		|
| accuracy, recognition rate(æº–ç¢ºç‡)		| `$ \frac{TP + TN}{P + N}$` |
| error rate, misclassification rate		| `$ \frac{FP + FN}{P + N}$`	|
| sensitivity, true positive rate, recall	| `$ \frac{TP}{P}$`		|
| specificity, true negative rate			| `$ \frac{TN}{N}$`		|
| precision(ç²¾æº–ç‡)							| `$ \frac{TP}{TP + FP}$`	|
| F, `$F_1$`, F-score, harmonic mean of precision and recall	| `$\frac{2\times precision \times recall}{precision + recall}$` |
| `$F_\beta$`, where `$\beta$` is a non-negative real number | `$\frac{(1 + \beta^2)\times precision \times recall}{\beta^\times precision + recall}$` |
</script></section>
<section data-markdown><script type="text/template">
## Accuracy and Error Rate
- `$$
\begin{array}{c|cc|c|c}
~ & é æ¸¬ & (predict) & Total & recognition (\%)\\ \hline
å¯¦éš› & é™½æ€§ & é™°æ€§ & ~ & ~\\
æ„ŸæŸ“ & \underline{259} & 41 & 300 & 86.33(recall \%)\\
æ²’æ„ŸæŸ“ & 22 & \underline{278}  & 300 & 92.67(specificity \%)\\ \hline
Total & 281 & 319 & 600 & 89.5 (accuracy \%)
\end{array}
$$`	
- æ„ŸæŸ“çš„éŒ¯èª¤ç‡: `$ \frac{41}{300}\times 100\% = 13.67\%$`
- æ²’æœ‰æ„ŸæŸ“çš„éŒ¯èª¤ç‡: `$ \frac{22}{300}\times 100\% = 7.33\%$`
- æª¢æ¸¬éŒ¯èª¤ç‡(error rate): `$\frac{FP + FN}{P+ N} = \frac{22 + 41}{300 + 300} \times 100\% = 10.5\%$`
</script></section>
<section data-markdown><script type="text/template">
## Precision, Recall and F-measures
- Precision: `$ \frac{TP}{TP + FP}$`, exactness â€“ what `$\%$` of tuples that the classifier labeled as positive are actually positive
	- `$Precision = \frac{259}{281} = 92.17\%$`
- Recall: `$ \frac{TP}{P}$`, completeness â€“ what `$\%$` of positive tuples did the classifier label as positive?
	- `$Recall = \frac{259}{300} = 86.33\%$`
- `$F_1$` or F-score:  `$\frac{2\times precision \times recall}{precision + recall}$`, harmonic mean of precision and recall,
	- `$F_1 = \frac{2\times 0.9217\times 0.8633}{0.9217 + 0.8633} = 89.15\%$`
</script></section>
<section data-markdown><script type="text/template">
## ROC Curves(1/3)
- Receiver operating characteristic(ROC) curves are a useful **visual tool** for **comparing two classification models**. 
- ROC curves come from signal detection theory that was developed during **World War II** for the **analysis of radar images**.
- An ROC curve for a given model shows the trade-off(å–æ¨) between the **`$true \;positive\; rate (TPR)$`** and the **`$false\; positive\; rate(FPR)$`**.
	- *TPR* is the **proportion of positive (or â€œyesâ€) tuples** that are **correctly labeled** by the model;
	- *FPR* is the **proportion of negative (or â€œnoâ€)** tuples that are **mislabeled as positive**.
</script></section>
<section data-markdown><script type="text/template">
## ROC Curves(2/3)
- Given that *TP, FP, P*, and *N* are the number of true positive, false positive, positive, and negative tuples, respectively.
- we know that `$TPR = \frac{TP}{P}$`, which is sensitivity. Furthermore, `$FPR = \frac{FP}{N} = 1 - specificity$`.
- For a two-class problem, an ROC curve allows us to visualize the trade-off between the rate at which the model
can accurately recognize positive cases versus the rate at which it mistakenly identifies negative cases as positive for different portions of the test set.
- Any increase in _TPR_ occurs at the cost of an increase in _FPR_. **The area under the
ROC curve(AUC) is a measure of the accuracy of the model**.
</script></section>
<section data-markdown><script type="text/template">
## ROC Curves(3/3)
- The ROC curves of two classification models, `$M_1$` and `$M_2$`. The diagonal shows where, for every
true positive, we are equally likely to encounter a false positive. 
- The closer an ROC curve is to the diagonal line, the less accurate the model is. Thus, **`$M_1$` is more accurate here**.
![](/images/datamining/roc.png)
</script></section>
<section data-markdown><script type="text/template">
## Issues Affecting Model Selection
- **Accuracy**(æº–ç¢ºæ€§)
	- classifier accuracy: predicting class label
- **Speed**
	- time to construct the model (training time)
	- time to use the model (classification/prediction time)
- **Robustness**(å¼·éŸŒæ€§): handling noise and missing values
- **Scalability**(æ“´å±•æ€§): efficiency in disk-resident databases 
- **Interpretability**(è§£é‡‹æ€§)
	- understanding and insight provided by the model
- Other measures, e.g., goodness of rules, such as decision tree size or compactness of classification rules
</script></section>
</section><!--end block-->

</div>
</div>

<script src="/revealjs/lib/js/head.min.js"></script>
<script src="/revealjs/dist/reveal.js"></script>
<script src="/revealjs/plugin/zoom/zoom.js"></script>
<script src="/revealjs/plugin/notes/notes.js"></script>
<script src="/revealjs/plugin/search/search.js"></script>
<script src="/revealjs/plugin/markdown/markdown.js"></script>
<script src="/revealjs/plugin/highlight/highlight.js"></script>
<script src="/revealjs/plugin/math/math.js"></script>
<script src="/revealjs/plugin/menu/menu.js"></script>
<script src="/revealjs/plugin/chalkboard/plugin.js"></script>
<script src="/revealjs/plugin/customcontrols/plugin.js"></script>
<script src="/revealjs/plugin/animate/svg.min.js"></script>
<script src="/revealjs/plugin/animate/plugin.js"></script>

<script>
Reveal.initialize({
controls: true,
progress: true,
history: true,
center: true,
slideNumber: true,
mouseWheel: true,
transition: 'slide', // none/fade/slide/convex/concave/zoom

menu: {
	side: 'left',
	width: 'normal',
	numbers: false,
	titleSelector: 'h1, h2, h3, h4, h5, h6',
	useTextContentForMissingTitles: false,
	hideMissingTitles: false,
	markers: true,
	custom: true,
	themes: true,
	themesPath: '/revealjs/dist/theme/',
	transitions: true,
	openButton: true,
	openSlideNumber: false,
	keyboard: true,
	sticky: false,
	autoOpen: true,
	delayInit: false,
	openOnInit: false,
	loadIcons: true,
	
	custom: [
			{ title: 'TOC', icon: '<i class="fa fa-external-link-alt">', src: 'links.html' },
			{ title: 'About', icon: '<i class="fa fa-info">', content: '<p>Slides for teaching Office Suite Softwar</p>' }
	]
},

customcontrols: {
	controls: [
	{
		id: 'toggle-overview',
		title: 'Toggle overview (O)',
		icon: '<i class="fa fa-th"></i>',
		action: 'Reveal.toggleOverview();'
	},
	{ icon: '<i class="fa fa-pen-square"></i>',
		title: 'Toggle chalkboard (B)',
		action: 'RevealChalkboard.toggleChalkboard();'
	},
	{ icon: '<i class="fa fa-pen"></i>',
		title: 'Toggle notes canvas (C)',
		action: 'RevealChalkboard.toggleNotesCanvas();'
	}
	]
},

toolbar: {
	// Specifies where the toolbar will be shown: 'top' or 'bottom'
	position: 'bottom',

	// Add button to toggle fullscreen mode for the presentation
	fullscreen: true,

	// Add button to toggle the overview mode on and off
	overview: true,

	// Add button to pause (hide) the presentation display
	pause: true,

	// Add button to show the speaker notes
	notes: false,

	// Add button to show the help overlay
	help: false,

	// If true, the reveal.js-menu will be moved into the toolbar.
	// Set to false to leave the menu on its own.
	captureMenu: true,

	// If true, the playback control will be moved into the toolbar.
	// This is only relevant if the presentation is configured to autoSlide.
	// Set to false to leave the menu on its own.
	capturePlaybackControl: true,

	// By default the menu will load it's own font-awesome library
	// icons. If your presentation needs to load a different
	// font-awesome library the 'loadIcons' option can be set to false
	// and the menu will not attempt to load the font-awesome library.
	loadIcons: true
},

// Optional reveal.js plugins
plugins: [ RevealZoom, RevealNotes, RevealSearch, RevealMarkdown, RevealHighlight, RevealAnimate, RevealMenu, RevealCustomControls, RevealChalkboard, RevealMath.KaTeX ],

dependencies: [
//{ src: '/revealjs/plugin/toolbar/toolbar.js' }
]
});

</script>

</body>
</html>
