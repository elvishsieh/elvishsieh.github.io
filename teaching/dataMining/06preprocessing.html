<!doctype html>
<html lang="zh-Hant-TW">

<head>
<meta charset="utf-8">

<title>資料預處理 (Data Preprocessing)</title>

<meta name="description" content="Tutorial of web design for primer">
<meta name="author" content="Elvis Hsieh">

<meta name="apple-mobile-web-app-capable" content="yes" />
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

<link rel="stylesheet" href="/revealjs/dist/reset.css">
<link rel="stylesheet" href="/revealjs/dist/reveal.css">
<link rel="stylesheet" href="/revealjs/dist/theme/black.css" id="theme">
<link rel="stylesheet" href="/revealjs/plugin/chalkboard/style.css">
<link rel="stylesheet" href="/revealjs/plugin/customcontrols/style.css">
<link rel="stylesheet" href="/css/custom4revealjs.css">
<!-- Code syntax highlighting -->
<link rel="stylesheet" href="/highlightjs/styles/monokai.min.css">   
<link rel="stylesheet" href="/css/style4font.css">
<!-- Printing and PDF exports -->
<script>
var link = document.createElement( 'link' );
link.rel = 'stylesheet';
link.type = 'text/css';
link.href = window.location.search.match( /revealjs/print-pdf/gi ) ? '/revealjs/dist/print/pdf.css' : '/revealjs/dist/print/paper.css';
document.getElementsByTagName( 'head' )[0].appendChild( link );
</script>

<!--[if lt IE 9]>
<script src="reveal-js/lib/js/html5shiv.js"></script>
<![endif]-->
</head>
<body>

<div class="reveal">

<!-- Any section element inside of this container is displayed as a slide -->
<div class="slides">

<section><!--start block-->
<section data-markdown><script type="text/template">
# Data Preprocessing: An Overview
</script></section>
<section data-markdown><script type="text/template">
## Why Preprocess the Data? (1/2)
- Data have quality if they satisfy the requirements of the intended use. There are many factors comprising data quality, including **accuracy, completeness, consistency, timeliness, believability**, and **interpretability**.
- Measures for data quality: A multidimensional view
	- **Accuracy**: correct or wrong, accurate or not
	- **Completeness**: not recorded, unavailable, …
	- **Consistency**: some modified but some not, dangling, …
	- **Timeliness**: timely update? 
	- Believability: how trustable the data are correct?
	- Interpretability: how easily the data can be understood?
</script></section>
<section data-markdown><script type="text/template">
## Why Preprocess the Data? (2/2)
- Let we have two tables from database as the following
|PID 	| Name 	| Gender	| TEL 		| Addr. 	|	Married | PG|
| :--:	| :--:	| :--:		| :--:		 	| :--:		| :--:		| :--:	|
| 12001	| **Mark**	| male		| **0921654789**| Taichung	| No		|	No 	|
| 12002	| Janie	| female	| 0925651234 	| Taipei	| _No_		| _Yes_	|
| 12003	| Danny	| **male**	| **0937654789**| Taipei	| Yes		| **Yes**|
|		|		|			|				|			|			|		|
|PID 	| Name 	| Section	| TEL 			|PSON 		| Salary 	| Bonus	|
| 12001	| **Mark**| Acc.		| **0982123785**| E			| 3000		|	No 	|
| 12002	| Janie	| Affair	| 0925651234 	| E			| **-2500**		|	Yes	|
| 12003	| Danny	| Acc.		| 			 	| M			| 4200		|	Yes	|
- **Deleted** instance(record, tuple) or **modified** and **edited** the value of instance for data cleaning, reduction, or consistency.  
</script></section>
<section data-markdown><script type="text/template">
## Data Preprocessing Major Tasks
- **Data cleaning**
	- Fill in missing values, smooth noisy data, identify or remove outliers, and resolve inconsistencies
- **Data integration**
	- Integration of multiple databases, data cubes, or files
- **Data reduction**
	- Dimensionality reduction
	- Numerosity reduction
	- Data compression
- Data transformation and data discretization
	- **Normalization** 
	- Concept hierarchy generation
</script></section>
</section><!--end block-->

<section><!--start block-->
<section data-markdown><script type="text/template">
# Data Cleaning
</script></section>
<section data-markdown><script type="text/template">
## Data in the Real World
- Data in the Real World is **Dirty**: Lots of potentially incorrect data, e.g., instrument faulty, 
human or computer error, transmission error.
- **Incomplete**:  e.g., Occupation=“ ” (missing data)
- **Noisy**: containing noise, errors, or outliers
	- e.g., Salary=“−10” (an error)
- **Inconsistent**: e.g., Age=“42”, Birthday=“03/07/2010”;
 Was rating “1, 2, 3”, now rating “A, B, C”; discrepancy between duplicate records
- Intentional (e.g., disguised missing data)
	- Jan. 1 as everyone’s birthday?
</script></section>
<section data-markdown><script type="text/template">
## Incomplete (Missing) Data
- Data is not always available
	- E.g., many tuples **have no recorded value** for several attributes, such as **customer income** in sales data
- Missing data may be due to 
	- Equipment malfunction
	- **Inconsistent** with other recorded data and **thus deleted**
	- Data not entered due to **misunderstanding**
	- Certain data may **not be considered important** at the time of entry
	- Not register history or changes of the data
- Missing data may **need to be inferred**
</script></section>
<section data-markdown><script type="text/template">
## How to Handle Missing Data?
- **Ignore the tuple**: usually done when class label is missing (when doing classification)—not effective when the % of missing values per attribute varies considerably
- Fill in the missing value **manually**: **tedious + infeasible**?
- Fill in it automatically with
	- A global constant : e.g., “unknown”, a new class?! 
	- The **attribute mean**
	- The attribute **mean for all samples** belonging to the same class: smarter
	- The most probable value: inference-based such as **Bayesian formula** or **decision tree**
</script></section>
</section><!--end block-->

<section><!--start block-->
<section data-markdown><script type="text/template">
# Noisy Data
</script></section>
<section data-markdown><script type="text/template">
## What is noise?
- Noise is a random error or variance in a measured variable
- Incorrect attribute values may be due to
	- Faulty data collection instruments
	- Data **entry problems**
	- Data **transmission problems**
	- Technology limitation
	- Inconsistency in naming convention 
- Other data problems which require data cleaning
	- **Duplicate** records
	- **Incomplete** data
	- **Inconsistent** data
</script></section>
<section data-markdown><script type="text/template">
## How to Handle Noisy Data?
- Binning
	- Binning methods smooth a sorted data value, that is, the values around it. 
	The sorted values are **distributed into a number of “buckets,” or bins**.
	- Binning methods are smoothing by **bin means**, **medians** and **boundaries** for data smoothing
- Regression
	- Smooth by fitting the data into regression functions
- Clustering
	- Detect and remove outliers
- Combined **computer and human inspection**
	- Detect suspicious values and check by human (e.g., deal with possible outliers)
</script></section>
<section data-markdown><script type="text/template">
## Data Cleaning as a Process (1/2)
- Data discrepancy detection
	- Use metadata (e.g., domain, range, dependency, distribution)
	- Check field overloading(4 bits < 17) 
	- Check uniqueness rule, consecutive rule and null rule
- Use commercial tools
	- Data scrubbing: use simple **domain knowledge** (e.g., **postal code, spell-check**) to detect errors and make corrections
	- Data auditing: by analyzing data to discover rules and relationship to detect violators (e.g., correlation and clustering to find outliers)
</script></section>
<section data-markdown><script type="text/template">
## Data Cleaning as a Process (2/2)
- Data migration and integration
	- Data migration tools: allow transformations to be specified
	- ETL (**Extraction/Transformation/Loading**) tools: allow users to specify transformations through a graphical user interface
- Integration of the two processes
	- Iterative and interactive (e.g., [Potter's Wheels](http://control.cs.berkeley.edu/abc/))
</script></section>
<section data-markdown><script type="text/template">
## Data Cleaning Tools
- [OpenRefine](https://openrefine.org/)  is a powerful free, open source tool for working with messy data: 
	cleaning it; transforming it from one format into another; and extending it with web 
	services and external data.
- [Melissa Clean Suite](https://www.melissa.com/crm-suite): Our Clean Suite for Salesforce & Microsoft Dynamics CRM will easily keep all your global People Data.
- [IBM Infosphere Quality Stage](https://www.ibm.com/products/infosphere-qualitystage) is designed to support your data quality and information governance initiatives.
The solution helps you deliver quality data for your big data, business intelligence, data warehousing, application migration and master data management projects.
</script></section>
<section data-markdown><script type="text/template">
## Data Cleaning with Excel (1/4)
- Delete blank line
![](/images/datamining/blankLine.png)
</script></section>
<section data-markdown><script type="text/template">
## Data Cleaning with Excel (2/4)
- Delete space(trim)
![](/images/datamining/delSpace.png)
</script></section>
<section data-markdown><script type="text/template">
## Data Cleaning with Excel (3/4)
- Standard letter(proper or upper)
![](/images/datamining/upper.png)
</script></section>
<section data-markdown><script type="text/template">
## Data Cleaning with Excel (4/4)
- Delete duplicate line
![](/images/datamining/duplicate.png)
</script></section>
</section><!--end block-->

<section><!--start block-->
<section data-markdown><script type="text/template">
# Data Integration
</script></section>
<section data-markdown><script type="text/template">
## Data integration problem and Detection
- Data integration combines data from multiple sources into a coherent data store.
	- Schema integration: e.g., _A.cust-id_ `$\equiv$` _B.cust-#_
	- Integrate metadata from different sources
- Entity identification problem
	- Identify real world entities from multiple data sources, e.g., **Bill Clinton = William Clinton**
- Detecting and resolving data value conflicts
	- The entity, attribute values from different sources are different, because was different representations, **different scales**, e.g., **metric vs. British units**
</script></section>
<section data-markdown><script type="text/template">
## Handling Redundancy in Data Integration
- Redundant data occur **often when integration of multiple databases**
	- Object identification:  The same attribute or object may have different names in different databases
	- Derivable data: One attribute may be a “derived” attribute in another table, e.g., annual revenue
- Redundant attributes may be able to be detected by **correlation analysis** and **covariance analysis**
- Careful integration of the data **from multiple sources** may help reduce/avoid **redundancies and inconsistencies** and improve mining speed and quality
</script></section>
<section data-markdown><script type="text/template">
# Correlation Analysis
</script></section>
<section data-markdown><script type="text/template">
## Correlation Analysis for Nominal Data
- **Redundancy** is another important issue in data integration. Some redundancies can be **detected by correlation analysis**.
- For **nominal data**, we use the **`$\chi^2$` (chi-square test, 卡方檢定)**
	- Hypothesis: Null Hypothesis(虛無檢定), Alternative Hypothesis(對立檢定)
	- 翻轉教學學生學習成效提升10%；米粉純米比率占不到 5%
- For **numeric attributes**, we can use the _correlation coefficient_ and _covariance_, both of which access how one attribute's 
	values vary from those of another.
</script></section>
<section data-markdown><script type="text/template">
## `$\chi^2$` Correlation Test for Nominal Data (1/2)
- Suppose **`$O_i$` is observed frequencies** and **`$E_i$` is expected frequencies**. **Chi-square Test** is
`$
	\chi^2 = \sum^{n}_{i=1} \frac{(O_i - E_i)^2}{E_i}
$`

- For nominal data, a correlation relationship between two attributes, _A_ and _B_. Suppose _A_ has _c_ distinct values, namely `$a_1, a_2, \cdots a_c$`.
_B_ has _r_ distinct values, namely `$b_1, b_2, \cdots b_r$`. **The Pearson `$\chi^2$` statistic** is computed as
`$$
	\chi^2 = \sum^{c}_{i=1} \sum^{r}_{j=1} \frac{(O_{ij} - E_{ij})^2}{E_{ij}}
$$`

</script></section>
<section data-markdown><script type="text/template">
## `$\chi^2$` Correlation Test for Nominal Data (2/2)
- `$E_{ij}$` is the expected frequency of `$(A_i, B_j)$`, which can be computed as
`$
E_{ij} = \frac{count(A = a_i) \times count(B = b_j)}{n}
$`
- Where **_n_ is the number of data tuples**, which is computed over all of the **`$(r\times c)$`** cells.
- The `$\chi^2$` statistic tests the hypothesis that **_A_ and _B_ are independent**, that is, there is **no
correlation** between them. The test is based on a significance level, with **`$(r-1)\times (c-1)$` degrees of freedom**
</script></section>
<section data-markdown><script type="text/template">
## Example of `$\chi^2$` Correlation Test
- Suppose that a group of **1500 people was surveyed**. The gender of each person was noted. Each person was polled as
to whether his or her preferred type of reading material was fiction or nonfiction.
![](/images/datamining/table31.png)
</script></section>
<section data-markdown><script type="text/template">
## Continue above slide (1/2)
- We have two attributes, **gender and preferred reading**. The observed frequency is summarized in the contingency table shown in Table 3.1,
 where **the numbers in parentheses are the expected frequencies**.
- The expected frequency for the cell (male, fiction) is
`$
E_{ij} = \frac{count(male) \times count(fiction)}{n} = \frac{300\times 450}{1500} = 90
$`
- The `$\chi^2$` Chi-square test is
`$$
\begin{align*}
\chi^2 & = \frac{(250-90)^2}{90} + \frac{(50-210)^2}{210} + \frac{(200-360)^2}{360}\\
 		& + \frac{(1000-840)^2}{840} = 507.93
\end{align*}
$$`
</script></section>
<section data-markdown><script type="text/template">
## Continue above slide (2/2)
- For this `$2 \times 2$` table, the degrees of freedom are `$(2-1)\times (2-1) = 1$`. For 1 degree of freedom, i.e, `$df = 1$`.
- We look up the `$\chi^2$` [chi-square distribution table](./Table_A5_ChiSquared.pdf), which the `$\chi^2$` value(507.93) is more than the value of chi-square distribution table,
where the row is 1 (df = 1) in the table.
- Since our computed value is above this, we can **reject the hypothesis** that **gender and preferred reading** are **independent** and conclude
that the two attributes are (strongly) correlated for the given group of people.
</script></section>
</section><!--end block-->

<section><!--start block-->
<section data-markdown><script type="text/template">
# Covariance and Correlation Coefficient
</script></section>
<section data-markdown><script type="text/template">
## Correlation between objects
- Correlation **measures the linear relationship** between objects. We standardize 
data objects, _A_ and _B_, and a set of n observations `${(a_1, b_1), \cdots , (a_n, b_n)}$`, then the `$k_{th}$`correlation between `$(a_k, b_k)$` **take their dot product**
`$ Correlation(a_k, b_k)  = a_k' \cdot b_k' $`, <br /> where
`$a_k' =\frac{ a_k - mean(A)}{std(B)}$`,
`$b_k' =\frac{ b_k - mean(B)}{std(B)}$`
- To compute correlation of _A_ and _B_ object 
`$$
\begin{align*}
	Correlation(A, B) & = A' \cdot B'\\
	& = \frac{\sum^n_{k=1} (a_k - \overline{a})\cdot \sum^n_{k=1}(b_k - \overline{b})}{\sigma_{A} \sigma_{B}}
\end{align*}
$$`
</script></section>
<section data-markdown><script type="text/template">
## Covariance of Numeric Data (1/2)
- **Consider two numeric attributes _A_ and _B_**, and a set of n observations `${(a_1, b_1), \cdots , (a_n, b_n)}$`. 
The mean values of _A_ and _B_, respectively, are also known as the **expected values** on _A_ and _B_, that is,
`$ E(A) = \overline{A} = \frac{1}{n} \sum^n_{k=1} a_k$` and `$ E(B) = \overline{B} = \frac{1}{n} \sum^n_{k=1} b_k$`
- The **covariance between _A_ and _B_ is defined** as 
`$$
\begin{align*}
	Cov(A, B) & = E((A - \overline{A})\cdot (B - \overline{B}))\\
			& = \frac{1}{(n-1)} \sum^n_{k=1} (a_k - \overline{A})(b_k - \overline{B})\\
			& = E(A\cdot B) - \overline{A} \cdot \overline{B}
\end{align*}
$$`
</script></section>
<section data-markdown><script type="text/template">
## Covariance of Numeric Data (2/2)
- For two attributes _A_ and _B_ that tend to change together, if **A is larger than `$\overline{A}$`** (the
expected value of _A_), **then _B_ is likely to be larger than `$\overline{B}$`** (the expected value of B).
Therefore, the **covariance between _A_ and _B_ is positive**.
- On the other hand, if one of the attributes tends to be above its expected value when the other attribute is below its
expected value, then the **covariance of _A_ and _B_ is negative**.
- If **_A_ and _B_ are independent** (i.e., they do not have correlation), then `$E(A\cdot B) = E(A)\cdot E(B)$`. 
Therefore, the covariance is `$Cov(A,B) = E(A\cdot B) - \overline{A} \cdot \overline{B} = E(A)\cdot E(B) - \overline{A}\cdot \overline{B} = 0$`. **Note `$\mapsto \overline{A}\cdot \overline{B}\not = \overline{A}\overline{B}$`**
</script></section>
<section data-markdown><script type="text/template">
## Why `$\overline{A}\cdot \overline{B}\not = \overline{A}\overline{B}$` ?
- Suppose _A_ and _B_ objects have a set of observations `$(1, 3, 5)$` and `$(2, 4, 6)$` respectively.
- To compute `$\overline{A}\cdot \overline{B}$` is 
`$$
\begin{align*}
\overline{A}\cdot \overline{B} & = \frac{1 + 3 + 5}{3} \times \frac{2 + 4 + 6}{3} = 7\\
\end{align*}
$$`
- To compute `$\overline{A}\overline{B}$` is 
`$$
\begin{align*}
\overline{A\cdot}\overline{B} & = \frac{1\times 2 + 3\times 4 + 5\times 6}{3}= \frac{44}{3} \\
\end{align*}
$$`
</script></section>
<section data-markdown><script type="text/template">
## Correlation Coefficient (1/2)
- **For numeric attributes**, we can evaluate the correlation between two attributes, A and B, by computing the correlation coefficient 
(also known as **Pearson’s product moment coefficient**).
- The **Pearson’s correlation coefficient** is <br />
`$
\rho_{A, B} = \frac{Cov(A, B)}{\sigma_{A} \cdot \sigma_{B}} = \frac{\sum^n_{i=1} (a_i - \overline{A})(b_i - \overline{B})}{(n-1)\cdot \sigma_{A} \cdot \sigma_{B}}
$` 
- Where _n_ is the number of tuples, `$a_i$` and `$b_i$` are the respective values of _A_ and _B_ in tuple _i_,
`$\overline{A}$` and `$\overline{B}$` are the respective mean values, 
`$\sigma_{A} = \sqrt{\frac{1}{(n-1)} \sum^n_{i=1} (a_i - \overline{A})^2}$`([不偏樣本](https://zh.wikipedia.org/zh-tw/%E6%96%B9%E5%B7%AE))
and `$\sigma_{B}$`are the respective standard deviations.
</script></section>
<section data-markdown><script type="text/template">
## Correlation Coefficient (2/2)
- The Pearson’s correlation coefficient is <br />
`$
\rho_{A, B} = \frac{\sum^n_{i=1} (a_i - \overline{A})(b_i - \overline{B})}{(n-1)\cdot \sigma_{A} \cdot \sigma_{B}}
	= \frac{\sum^n_{i=1} (a_i\cdot b_i) - n\cdot\overline{A} \cdot\overline{B}}{(n-1)\cdot \sigma_{A} \cdot \sigma_{B}}
$`
- Note that `$-1 \le \rho_{A,B} \le +1$`. If `$\rho_{A,B}$` is greater than 0, then _A_ and _B_ are positively
correlated, meaning that the values of _A_ increase as the values of _B_ increase. 
- **The higher the value, the stronger the correlation**. Hence, it may indicate that **may be removed as a redundancy**.
- If the resulting value is **equal to 0**, then **_A_ and _B_ are independent** and there is **no correlation** between them.
- If the resulting value is **less than 0**, then _A_ and _B_ are **negatively correlated**,
where the values of **one attribute increase** as the values of **the other attribute decrease**. 
</script></section>
<section data-markdown><script type="text/template">
## Example of Covariance Coefficient
- Consider Table 3.2, which presents a sim-plified example of stock prices observed at 
five time points for _AllElectronics_ and _HighTech_, a high-tech company. If the stocks 
are affected by the same industry trends, will their prices rise or fall together?
![](/images/datamining/table32.png)
</script></section>
<section data-markdown><script type="text/template">
## Continue above slide
- `$E(AllElectronics) = \frac{6+5+4+3+2}{5} = \frac{20}{5} = \$4$`
- `$E(HighTech) = \frac{20+10+14+5+5}{5} = \frac{54}{5} = \$10.8$`
- `$$
	\begin{align*}
	Cov(AE, HT) & = \frac{6\times 20 + 5\times 10 + 4\times 14 + 3\times 5 + 2\times 5}{5}\\
	& - 4\times 10.8\\
		& = 50.2 - 43.2 = 7
	\end{align*}
$$`
- Therefore, given the **positive covariance** we can say that **stock prices for both companies
rise together**.
</script></section>
<section data-markdown><script type="text/template">
## Visually Evaluating Correlation
![](/images/datamining/visualCorrelation.png)
</script></section>
</section><!--end block-->

</div>
</div>

<script src="/revealjs/lib/js/head.min.js"></script>
<script src="/revealjs/dist/reveal.js"></script>
<script src="/revealjs/plugin/zoom/zoom.js"></script>
<script src="/revealjs/plugin/notes/notes.js"></script>
<script src="/revealjs/plugin/search/search.js"></script>
<script src="/revealjs/plugin/markdown/markdown.js"></script>
<script src="/revealjs/plugin/highlight/highlight.js"></script>
<script src="/revealjs/plugin/math/math.js"></script>
<script src="/revealjs/plugin/menu/menu.js"></script>
<script src="/revealjs/plugin/chalkboard/plugin.js"></script>
<script src="/revealjs/plugin/customcontrols/plugin.js"></script>
<script src="/revealjs/plugin/animate/svg.min.js"></script>
<script src="/revealjs/plugin/animate/plugin.js"></script>

<script>
Reveal.initialize({
controls: true,
progress: true,
history: true,
center: true,
slideNumber: true,
mouseWheel: true,
transition: 'slide', // none/fade/slide/convex/concave/zoom

menu: {
	side: 'left',
	width: 'normal',
	numbers: false,
	titleSelector: 'h1, h2, h3, h4, h5, h6',
	useTextContentForMissingTitles: false,
	hideMissingTitles: false,
	markers: true,
	custom: true,
	themes: true,
	themesPath: '/revealjs/dist/theme/',
	transitions: true,
	openButton: true,
	openSlideNumber: false,
	keyboard: true,
	sticky: false,
	autoOpen: true,
	delayInit: false,
	openOnInit: false,
	loadIcons: true,
	
	custom: [
			{ title: 'TOC', icon: '<i class="fa fa-external-link-alt">', src: 'links.html' },
			{ title: 'About', icon: '<i class="fa fa-info">', content: '<p>Slides for teaching Office Suite Softwar</p>' }
	]
},

customcontrols: {
	controls: [
	{
		id: 'toggle-overview',
		title: 'Toggle overview (O)',
		icon: '<i class="fa fa-th"></i>',
		action: 'Reveal.toggleOverview();'
	},
	{ icon: '<i class="fa fa-pen-square"></i>',
		title: 'Toggle chalkboard (B)',
		action: 'RevealChalkboard.toggleChalkboard();'
	},
	{ icon: '<i class="fa fa-pen"></i>',
		title: 'Toggle notes canvas (C)',
		action: 'RevealChalkboard.toggleNotesCanvas();'
	}
	]
},

toolbar: {
	// Specifies where the toolbar will be shown: 'top' or 'bottom'
	position: 'bottom',

	// Add button to toggle fullscreen mode for the presentation
	fullscreen: true,

	// Add button to toggle the overview mode on and off
	overview: true,

	// Add button to pause (hide) the presentation display
	pause: true,

	// Add button to show the speaker notes
	notes: false,

	// Add button to show the help overlay
	help: false,

	// If true, the reveal.js-menu will be moved into the toolbar.
	// Set to false to leave the menu on its own.
	captureMenu: true,

	// If true, the playback control will be moved into the toolbar.
	// This is only relevant if the presentation is configured to autoSlide.
	// Set to false to leave the menu on its own.
	capturePlaybackControl: true,

	// By default the menu will load it's own font-awesome library
	// icons. If your presentation needs to load a different
	// font-awesome library the 'loadIcons' option can be set to false
	// and the menu will not attempt to load the font-awesome library.
	loadIcons: true
},

// Optional reveal.js plugins
plugins: [ RevealZoom, RevealNotes, RevealSearch, RevealMarkdown, RevealHighlight, RevealAnimate, RevealMenu, RevealCustomControls, RevealChalkboard, RevealMath.KaTeX ],

dependencies: [
//{ src: '/revealjs/plugin/toolbar/toolbar.js' }
]
});

</script>

</body>
</html>
