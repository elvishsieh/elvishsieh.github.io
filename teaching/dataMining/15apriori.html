<!doctype html>
<html lang="zh-Hant-TW">

<head>
<meta charset="utf-8">

<title>Apriori algorithm</title>

<meta name="description" content="Tutorial of web design for primer">
<meta name="author" content="Elvis Hsieh">

<meta name="apple-mobile-web-app-capable" content="yes" />
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

<link rel="stylesheet" href="/revealjs/dist/reset.css">
<link rel="stylesheet" href="/revealjs/dist/reveal.css">
<link rel="stylesheet" href="/revealjs/dist/theme/black.css" id="theme">
<link rel="stylesheet" href="/revealjs/plugin/chalkboard/style.css">
<link rel="stylesheet" href="/revealjs/plugin/customcontrols/style.css">
<link rel="stylesheet" href="/css/custom4revealjs.css">
<!-- Code syntax highlighting -->
<link rel="stylesheet" href="/highlightjs/styles/monokai.min.css">   
<link rel="stylesheet" href="/css/style4font.css">
<!-- Printing and PDF exports -->
<script>
var link = document.createElement( 'link' );
link.rel = 'stylesheet';
link.type = 'text/css';
link.href = window.location.search.match( /revealjs/print-pdf/gi ) ? '/revealjs/dist/print/pdf.css' : '/revealjs/dist/print/paper.css';
document.getElementsByTagName( 'head' )[0].appendChild( link );
</script>

<!--[if lt IE 9]>
<script src="reveal-js/lib/js/html5shiv.js"></script>
<![endif]-->
</head>
<body>

<div class="reveal">

<!-- Any section element inside of this container is displayed as a slide -->
<div class="slides">

<section><!--start block-->
<section data-markdown><script type="text/template">
# Apriori
</script></section>
<section data-markdown><script type="text/template">
## Apriori Property(1/2)
- Apriori is a seminal algorithm proposed by R. Agrawal and R. Srikant in 1994[AS94b].
- Apriori employs an iterative approach known as a level-wise search,
where k-itemsets are used to explore (k+1)-itemsets.
	- First, the set of frequent 1-itemsets is found by scanning the database to 
	accumulate the **count for each item**, and collecting those items that **satisfy _minimum support_**.
	The resulting set is denoted by `$L_1$`.
	- Next, **`$L_1$` is used to find `$L_2$`**, the set of frequent 2-itemsets, which is used to find `$L_3$`, and
	so on, **until no more frequent k-itemsets can be found**.
</script></section>
<section data-markdown><script type="text/template">
## Apriori Property(2/2)
- Finding of each `$L_k$` requires one full scan of the database.
- To improve the efficiency of the level-wise generation of frequent itemsets, an
important property called the Apriori property is used to reduce the search space.
- _Apriori property_ : **All nonempty subsets of a frequent itemset must also be frequent**.
- By definition, if an itemset `$I$` does not satisfy the minimum support threshold, `$min\_sup$`, then `$I$` is not frequent, that is, `$P(I) < min\_sup$`.
- If an item `$A$` is added to the itemset `$I$`, then the (`$I \cup A$`) itemset cannot occur more frequently than `$I$`. Therefore, `$I \cup A$` is not frequent either,`$ \rArr P(I \cup A) < min\_sup$`.
</script></section>
<section data-markdown><script type="text/template">
## How to use Apriori Property(1/3)
- “How is the Apriori property used in the algorithm?”
- let us look at how `$L_{k-1}$` is used to find `$L_k$` for `$k \leq 2$`. A two-step process is followed, consisting of **join and prune actions**.
1. **The join step**: To find `$L_k$`, a set of candidate `$k$`-itemsets is generated by joining `$L_{k-1}$` with itself. This set of candidates is
denoted `$C_k$`. Let `$l_1$` and `$l_2$` be itemsets in `$L_{k-1}$`. The notation `$l_{i}[j]$` refers to the `$j_{th}$` item in 
`$l_i$` (e.g., **`$l_{1}[k-2]$` refers to the second to the last item in `$l_1$`)**.
For the (`$k-1$`)-itemset, `$l_i$` , this means that **the items are sorted such that `$l_i[1] < l_i[2] < \cdots < l_i[k-1]$`**.
</script></section>
<section data-markdown><script type="text/template">
## How to use Apriori Property(2/3)
1. The join, **`$L_{k-1} \Join L_{k-1}$`**, is performed, where members of `$L_{k-1}$` are joinable if their first (`$k-2$`) items are in common.
That is, members `$l_1$` and `$l_2$` of `$L_{k-1}$` are joined if `($l_1[1] = l_2[1]) \wedge(l_1[2] = l_2[2]) \wedge \cdots \wedge (l_1[k-2]=l_2[k-2])
\wedge (l_1[k-1] < l_2[k-1])$`. **The condition `$l_1[k-1] < l_2[k-1]$`** ensures that no duplicates are generated.
The resulting itemset formed by **joining `$l_1$` and `$l_2$` is `$\{l_1[1], l_1[2], \cdots, l_1[k-2], l_1[k-1], l_2[k-1]\}$`**.
2. The prune step: `$C_k$` is a superset of `$L_k$`, that is, its members may or may not be
frequent, but all of the frequent k-itemsets are included in `$C_k$`.
</script></section>
<section data-markdown><script type="text/template">
## How to use Apriori Property(3/3)
2. A database scan to determine the count of each candidate in `$C_k$` would
result in the determination of `$L_k$` (i.e., all candidates having a count no less than the 
_min_sup count_ are frequent by definition). **`$C_k\in L_k$` can be huge**, and so this could involve **heavy computation**. To reduce the 
size of `$C_k$`, the Apriori property is used as follows. **Any (k-1)-itemset that is not
frequent cannot be a subset of a frequent `$k$`-itemset**. Hence, if any (k-1)-subset of a
candidate k-itemset is not in `$L_{k-1}$`, then the candidate cannot be frequent either 
and so can be removed from `$C_k$`.This subset testing can be done quickly by maintaining a 
hash tree of all frequent itemsets.
</script></section>
<section data-markdown><script type="text/template">
## Cartesian Product
- **`$L_1\Join L_1$` is equivalent to `$L_1 \times L_1$`**, since the definition of `$L_k \Join L_k$` 
requires the two joining itemsets to share `$k - 1 = 0$` items.
<figure style="float: right">
	<img src="/images/datamining/cartesianProduct.png" width="90%" alt="cartesianProduct">
	</figure>
- The Cartesian product of two sets `$A$` and `$B$`, denoted `$A\times B$`, 
is the set of all ordered pairs `$(a, b)$` where `$a$` is in `$A$` and `$b$` is in `$B$`.
- For example: A = {1,2}; B = {3,4}
	- **A × B = {1,2} × {3,4} = {(1,3), (1,4), (2,3), (2,4)}**
	- B × A = {3,4} × {1,2} = {(3,1), (3,2), (4,1), (4,2)}
</script></section>
</section><!--end block-->

<section><!--start block-->
<section data-markdown><script type="text/template">
# Apriori's Example
</script></section>
<section data-markdown><script type="text/template">
## An example of Apriori(1/8)
- Let's look at a concrete example, based on the AllElectronics transaction database, D, of as follow figure.
There are nine transactions in this database, that is, `$|D| = 9$`.
![](/images/datamining/apriori.png)
</script></section>
<section data-markdown><script type="text/template">
## An example of Apriori(2/8)
1. Suppose that the minimum support count required is 2, that is, `$min\_sup = 2$`.
![](/images/datamining/apriori2.png)
</script></section>
<section data-markdown><script type="text/template">
## An example of Apriori(3/8)
2. The corresponding relative support is `$2/9 = 22\%$`. The set of frequent 1-itemsets, 
`$L_1$`, can then be determined. In our example, all of the candidates in `$C_1$` satisfy _minimum support_.
3. To discover the set of frequent 2-itemsets, `$L_2$`, the algorithm uses the join `$L_1 \Join L_1$` to
generate a candidate set of 2-itemsets, `$C_2$`. `$C_2$` consists of 
`$\begin{pmatrix}
|L_1|\\ 2
\end{pmatrix}$` 2-itemsets.
	- `$L_1 \Join L_1$` is equivalent to `$L_1 \times L_1$`, since the definition of `$L_k \Join L_k$` requires the two joining itemsets to share `$k -1 = 0$` items.
</script></section>
<section data-markdown><script type="text/template">
## An example of Apriori(4/8)
4. Next, the transactions in `$D$` are scanned and the support count of each candidate itemset in `$C_2$` is accumulated, as shown in the middle table
of the second row in the Figure.
5. The set of frequent 2-itemsets, `$L_2$`, is then determined, consisting of those candidate 2-itemsets in `$C_2$` having minimum support.
6. The generation of the set of the candidate 3-itemsets, `$C_3$`. From the join step, we first get `$C_3 = L_2 \Join L_2 = \{\{I1,I2,I3\},\{I1,I2,I5\}, \{I1,I3,I5\},\{I2,I3,I4\},$`
`$ \{I2,I3,I5\},\{I2,I4,I5\}\}$`.
</script></section>
<section data-markdown><script type="text/template">
## An example of Apriori(5/8)
6.  Based on the Apriori property that all subsets of a frequent itemset must also be frequent, we can determine that the four latter
candidates cannot possibly be frequent.
<dl>
<dt>(a)Join:</dt>
<dd> <a href="./15apriori.html#/0/6"> $C_3 = L_2 \Join L_2$</a> = {{I1, I2}, {I1, I3}, {I1, I5}, {I2, I3}, {I2, I4}, {I2, I5}} 
$\Join$ {{I1, I2}, {I1, I3}, {I1, I5}, {I2, I3}, {I2, I4}, {I2, I5}}
= {{I1, I2, I3}, {I1, I2, I5}, {I1, I3, I5}, {I2, I3, I4}, {I2, I3, I5}, {I2, I4, I5}}.</dd>
<dt>(b)Prune using the Apriori property: </dt>
<dd>All nonempty subsets of a frequent itemset must also be
frequent. Do any of the candidates have a subset that is not frequent?</dd>
</dl>
</script></section>
<section data-markdown><script type="text/template">
## An example of Apriori(6/8)
- The 2-item subsets of {I1, I2, I3} are {I1, I2}, {I1, I3}, and {I2, I3}. All 2-item subsets
	of {I1, I2, I3} are members of `$L_2$`. Therefore, keep {I1, I2, I3} in `$C_3$`.
- The 2-item subsets of {I1, I2, I5} are {I1, I2}, {I1, I5}, and {I2, I5}. All 2-item subsets of
{I1, I2, I5} are members of `$L_2$`. Therefore, keep {I1, I2, I5} in `$C_3$`.
- The 2-item subsets of {I1, I3, I5} are {I1, I3}, {I1, I5}, and {I3, I5}. {I3, I5} is not
a member of `$L_2$`, and so it is not frequent. Therefore, remove {I1, I3, I5} from `$C_3$`.
- The 2-item subsets of {I2, I3, I4} are {I2, I3}, {I2, I4}, and {I3, I4}. {I3, I4} is not a
member of `$L_2$`, and so it is not frequent. Therefore, remove {I2, I3, I4} from `$C_3$`.

</script></section>
<section data-markdown><script type="text/template">
## An example of Apriori(7/8)
- The 2-item subsets of {I2, I3, I5} are {I2, I3}, {I2, I5}, and {I3, I5}. {I3, I5} is not
a member of `$L_2$`, and so it is not frequent. Therefore, remove {I2, I3, I5} from `$C_3$`.
- The 2-item subsets of {I2, I4, I5} are {I2, I4}, {I2, I5}, and {I4, I5}. {I4, I5} is not a
member of `$L_2$`, and so it is not frequent. Therefore, remove {I2, I4, I5} from `$C_3$`.

(c) Therefore, **`$C_3$` = {{I1, I2, I3}, {I1, I2, I5}} after pruning
search strategy**. The resulting pruned version of `$C_3$` is shown in the first table of the
bottom row of [this Figure](./15apriori.html#/1/2).
</script></section>
<section data-markdown><script type="text/template">
## An example of Apriori(8/8)
7. The transactions in `$D$` are scanned to determine `$L_3$`, consisting of those candidate
3-itemsets in `$C_3$` having minimum support ([this Figure](./15apriori.html#/1/2)).
8. The algorithm uses `$L_3 \Join L_3$` to generate a candidate set of 4-itemsets, `$C_4$`. Although
the join results in {{I1, I2, I3, I5}}, **itemset {I1, I2, I3, I5} is pruned because its subset
{I2, I3, I5} is not frequent**. Thus, **`$C_4 = \varnothing$`**, and the algorithm terminates, having found
all of the frequent itemsets.
</script></section>
<section data-markdown><script type="text/template">
## $C_3 = L_2 \Join L_2$
![](/images/datamining/apriori3.png)
</script></section>
</section><!--end block-->

<section><!--start block-->
<section data-markdown><script type="text/template">
# Apriori Algorithm
</script></section>
<section data-markdown><script type="text/template">
## Apriori Algorithm(1/2)
![](/images/datamining/aprioriAlgorithm.png)
</script></section>
<section data-markdown><script type="text/template">
## Apriori Algorithm(2/2)
![](/images/datamining/aprioriAlgorithm2.png)
</script></section>
<section data-markdown><script type="text/template">
## The apriori *gen_procedure*
- The apriori *gen_procedure* generates the candidates and then uses the Apriori property to eliminate those having a subset that is not frequent (step 3).
- The apriori *gen_procedure* performs two kinds of actions, namely, **join and prune**, as described before.
	- In the join component, `$L_{k-1}$` is joined with `$L_{k-1}$` to generate potential candidates (steps 1-4).
	- The prune component (steps 5-7) employs the Apriori property to remove candidates that have a subset that is not frequent.
- The test for infrequent subsets is shown in procedure *has_infrequent* subset.
</script></section>
</section><!--end block-->

<section><!--start block-->
<section data-markdown><script type="text/template">
# Generating Association Rules
</script></section>
<section data-markdown><script type="text/template">
## Generating Association Rules from Frequent Itemsets
- Using [this Eq.](./14association.html#/1/5) for confidence, which we show again here
<p style="font-size: 26pt">$
	confidence(A \rArr B) = P(B|A) = \frac{support\_count(A \cup B)}{support\_count(A)}
	$
</p>
- Based on this equation, **association rules can be generated as follows**:
	- For each frequent itemset `$l$`, generate all nonempty subsets of `$l$`.
	- For every nonempty subset `$s$` of `$l$`, output the rule `$"s \rArr (l -s)"$` if `$\frac{support\_count(A \cup B)}{support\_count(A)} \geq min\_conf$`
</script></section>
<section data-markdown><script type="text/template">
## An example for Generating Association Rules(1/2)
- Let's try the _AllElectronics_ example in [previously Table](./15apriori.html#/1/1).
- The data contain **frequent itemset `$X = \{I1, I2, I5\}$.`** What are **the association rules that can be generated from** `$X$`? The nonempty subsets
of **`$X$` are `$\{I1, I2\}, \{I1, I5\}, \{I2, I5\}, \{I1\},\{I2\}$` and `$\{I5\}$`**
- The resulting association rules are as shown below:
<p style="font-size: 26pt">$\{I1, I2\} \rArr I5, confidence = 2/4 = 50\%$</p>
<p style="font-size: 26pt">$\{I1, I5\} \rArr I2, confidence = 2/2 = 100\%$</p>
<p style="font-size: 26pt">$\{I2, I5\} \rArr I1, confidence = 2/2 = 100\%$</p>
</script></section>
<section data-markdown><script type="text/template">
## An example for Generating Association Rules(2/2)
<p style="font-size: 26pt;padding:0 0 0 1em">$I1 \rArr \{I2, I5\}, confidence = 2/6 = 33\%$</p>
<p style="font-size: 26pt;padding:0 0 0 1em">$I2 \rArr \{I1, I5\}, confidence = 2/7 = 29\%$</p>
<p style="font-size: 26pt;padding:0 0 0 1em">$I5 \rArr \{I1, I2\}, confidence = 2/2 = 100\%$</p>

- If the **minimum confidence threshold is, say, `$70\%$`**, then only **the second, third, and last rules are output**, because these are the only ones  generated that are strong.
- Note that, unlike conventional classification rules, association rules can contain more than one conjunct in the right side of the rule.
</script></section>
</section><!--end block-->

<section><!--start block-->
<section data-markdown><script type="text/template">
# The Efficiency of Apriori
</script></section>
<section data-markdown><script type="text/template">
## Improving the Efficiency of Apriori(1/5)
- To **improvie the efficiency of Apriori-based mining** have been proposed that are summarized as follows:
- **Hash-based technique** (hashing itemsets into buckets): A hash-based technique can be used to reduce the size of the candidate k-itemsets, `$C_k$`, for `$k > 1$`.
	- For example, when scanning the database to generate the frequent 1-itemsets, `$L_1$`, we can generate all the 2-itemsets for each transaction, hash (i.e., map)
	them into the different buckets of a hash table structure, and increase the corresponding
	bucket counts (the Figure of next slide).
</script></section>
<section data-markdown><script type="text/template">
## Improving the Efficiency of Apriori(2/5)
- Hash table, `$H_2$`, for candidate 2-itemsets. This hash table was generated by scanning
[this Table's](./15apriori.html#/1/1) transactions while determining `$L_1$`. If the **minimum support count is, say, 3**, then
the itemsets in **buckets 0, 1, 3, and 4 cannot be frequent** and so they should not be included in `$C_2$`.
![](/images/datamining/hash.png)
</script></section>
<section data-markdown><script type="text/template">
## Improving the Efficiency of Apriori(3/5)
- **Transaction reduction** (reducing the number of transactions scanned in future iterations):**A transaction that does not contain any 
frequent `$k$`-itemsets cannot contain any frequent (`$k+1$`)-itemsets**. Therefore, such a transaction can be marked or removed
from further consideration because subsequent database scans for `$j$`-itemsets, where `$j > k$`, will not need to consider such a transaction.
- **Partitioning** (partitioning the data to find candidate itemsets):
</script></section>
<section data-markdown><script type="text/template">
## Improving the Efficiency of Apriori(4/5)
- It consists of two phases.
![](/images/datamining/partition.png)
</script></section>
<section data-markdown><script type="text/template">
## Improving the Efficiency of Apriori(5/5)
- **Sampling** (mining on a subset of the given data): The basic idea of the sampling
approach is to **pick a random sample `$S$`** of the given data `$D$`, and then **search for
frequent itemsets in `$S$` instead of `$D$`**.
- **Dynamic itemset counting** (adding candidate itemsets at different points during a
scan): In this variation, **new candidate itemsets can be added at any start point**, unlike **in Apriori**, which determines new
candidate itemsets only immediately **before each complete database scan**.
</script></section>
</section><!--end block-->

</div>
</div>

<script src="/revealjs/lib/js/head.min.js"></script>
<script src="/revealjs/dist/reveal.js"></script>
<script src="/revealjs/plugin/zoom/zoom.js"></script>
<script src="/revealjs/plugin/notes/notes.js"></script>
<script src="/revealjs/plugin/search/search.js"></script>
<script src="/revealjs/plugin/markdown/markdown.js"></script>
<script src="/revealjs/plugin/highlight/highlight.js"></script>
<script src="/revealjs/plugin/math/math.js"></script>
<script src="/revealjs/plugin/menu/menu.js"></script>
<script src="/revealjs/plugin/chalkboard/plugin.js"></script>
<script src="/revealjs/plugin/customcontrols/plugin.js"></script>
<script src="/revealjs/plugin/animate/svg.min.js"></script>
<script src="/revealjs/plugin/animate/plugin.js"></script>

<script>
Reveal.initialize({
controls: true,
progress: true,
history: true,
center: true,
slideNumber: true,
mouseWheel: true,
transition: 'slide', // none/fade/slide/convex/concave/zoom

menu: {
	side: 'left',
	width: 'normal',
	numbers: false,
	titleSelector: 'h1, h2, h3, h4, h5, h6',
	useTextContentForMissingTitles: false,
	hideMissingTitles: false,
	markers: true,
	custom: true,
	themes: true,
	themesPath: '/revealjs/dist/theme/',
	transitions: true,
	openButton: true,
	openSlideNumber: false,
	keyboard: true,
	sticky: false,
	autoOpen: true,
	delayInit: false,
	openOnInit: false,
	loadIcons: true,
	
	custom: [
			{ title: 'TOC', icon: '<i class="fa fa-external-link-alt">', src: 'links.html' },
			{ title: 'About', icon: '<i class="fa fa-info">', content: '<p>Slides for teaching Office Suite Softwar</p>' }
	]
},

customcontrols: {
	controls: [
	{
		id: 'toggle-overview',
		title: 'Toggle overview (O)',
		icon: '<i class="fa fa-th"></i>',
		action: 'Reveal.toggleOverview();'
	},
	{ icon: '<i class="fa fa-pen-square"></i>',
		title: 'Toggle chalkboard (B)',
		action: 'RevealChalkboard.toggleChalkboard();'
	},
	{ icon: '<i class="fa fa-pen"></i>',
		title: 'Toggle notes canvas (C)',
		action: 'RevealChalkboard.toggleNotesCanvas();'
	}
	]
},

toolbar: {
	// Specifies where the toolbar will be shown: 'top' or 'bottom'
	position: 'bottom',

	// Add button to toggle fullscreen mode for the presentation
	fullscreen: true,

	// Add button to toggle the overview mode on and off
	overview: true,

	// Add button to pause (hide) the presentation display
	pause: true,

	// Add button to show the speaker notes
	notes: false,

	// Add button to show the help overlay
	help: false,

	// If true, the reveal.js-menu will be moved into the toolbar.
	// Set to false to leave the menu on its own.
	captureMenu: true,

	// If true, the playback control will be moved into the toolbar.
	// This is only relevant if the presentation is configured to autoSlide.
	// Set to false to leave the menu on its own.
	capturePlaybackControl: true,

	// By default the menu will load it's own font-awesome library
	// icons. If your presentation needs to load a different
	// font-awesome library the 'loadIcons' option can be set to false
	// and the menu will not attempt to load the font-awesome library.
	loadIcons: true
},

// Optional reveal.js plugins
plugins: [ RevealZoom, RevealNotes, RevealSearch, RevealMarkdown, RevealHighlight, RevealAnimate, RevealMenu, RevealCustomControls, RevealChalkboard, RevealMath.KaTeX ],

dependencies: [
//{ src: '/revealjs/plugin/toolbar/toolbar.js' }
]
});

</script>

</body>
</html>
